{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate\n",
        "!pip install transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0hipq_iIb6g",
        "outputId": "3f98eb62-daf8-43a4-bd51-b61d5eeb4c59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.30.1-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n",
            "Successfully installed accelerate-0.30.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Correcting the path to use the full path from the root\n",
        "data_path = \"/content/drive/MyDrive/nlp final project/AnonymizedClinicalAbbreviationsAndAcronymsDataSet.txt\"\n",
        "\n",
        "try:\n",
        "    data = pd.read_csv(data_path, sep='|', header=None, names=[\n",
        "        \"Short_form\", \"Long_form\", \"Abbreviation\", \"Start_pos\", \"End_pos\", \"Section_info\", \"Context\"\n",
        "    ], encoding='ISO-8859-1')\n",
        "except UnicodeDecodeError:\n",
        "    data = pd.read_csv(data_path, sep='|', header=None, names=[\n",
        "        \"Short_form\", \"Long_form\", \"Abbreviation\", \"Start_pos\", \"End_pos\", \"Section_info\", \"Context\"\n",
        "    ], encoding='ISO-8859-1', errors='ignore')\n",
        "\n",
        "print(data.head())\n",
        "print(data.info())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ye0UtGj6JKuQ",
        "outputId": "591c8a29-5675-492c-e789-3059d66f442e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "  Short_form Long_form Abbreviation  Start_pos  End_pos  \\\n",
            "0         AB  abortion          AB.      231.0    233.0   \n",
            "1         AB  abortion          AB.      249.0    251.0   \n",
            "2         AB  abortion           AB      223.0    224.0   \n",
            "3         AB  abortion          AB.      194.0    196.0   \n",
            "4         AB  abortion           AB      114.0    115.0   \n",
            "\n",
            "                     Section_info  \\\n",
            "0                             NaN   \n",
            "1                             NaN   \n",
            "2                 PAST OB HISTORY   \n",
            "3  HISTORY OF THE PRESENT ILLNESS   \n",
            "4             PAST OB-GYN HISTORY   \n",
            "\n",
            "                                             Context  \n",
            "0  _%#NAME#%_ _%#NAME#%_ is a 29-year-old gravida...  \n",
            "1  She is now bleeding quite heavily. Ultrasound ...  \n",
            "2  ALLERGIES: Heparin and Imitrex. PAST OB HISTOR...  \n",
            "3  She had a pelvic ultrasound at Park Nicollet o...  \n",
            "4  On _%#MMDD2007#%_, normal anatomy with anterio...  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 37500 entries, 0 to 37499\n",
            "Data columns (total 7 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   Short_form    37000 non-null  object \n",
            " 1   Long_form     37500 non-null  object \n",
            " 2   Abbreviation  37047 non-null  object \n",
            " 3   Start_pos     37496 non-null  float64\n",
            " 4   End_pos       37496 non-null  float64\n",
            " 5   Section_info  36475 non-null  object \n",
            " 6   Context       37496 non-null  object \n",
            "dtypes: float64(2), object(5)\n",
            "memory usage: 2.0+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the 'Long_form' column of the dataframe into a list\n",
        "labels = data['Long_form'].tolist()\n",
        "\n",
        "# Convert the 'Context' column of the dataframe into a list\n",
        "texts = data['Context'].tolist()\n",
        "\n",
        "# Create a sorted list of unique labels\n",
        "label_list = sorted(set(labels))\n",
        "\n",
        "# Create a dictionary mapping each label to a unique index\n",
        "label_map = {label: idx for idx, label in enumerate(label_list)}\n",
        "\n",
        "# Create a dictionary to map indices back to labels for easier interpretation later\n",
        "inverse_label_map = {idx: label for label, idx in label_map.items()}\n",
        "\n",
        "# Print the mappings from labels to indices and vice versa\n",
        "print(\"Label Map:\", label_map)\n",
        "print(\"Inverse Label Map:\", inverse_label_map)\n",
        "\n",
        "# Print the total number of unique labels\n",
        "print(\"Total labels:\", len(label_map))\n",
        "print(\"Total Inverse Label:\", len(inverse_label_map))\n",
        "\n",
        "# Convert all labels in the original list to their corresponding indices\n",
        "labels_indexed = [label_map[label] for label in labels]\n",
        "\n",
        "# Import the train_test_split function from scikit-learn to split data into training and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the dataset into training and testing sets, with 20% of the data reserved as the test set\n",
        "texts_train, texts_test, labels_train, labels_test = train_test_split(\n",
        "    texts, labels_indexed, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqUfiXlGKlQ1",
        "outputId": "aad7062d-832c-4b9c-bf3c-581aca1237f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label Map: {'(PO Box) C4': 0, '(class) IA': 1, '(complement) component 3': 2, '(complement) component 4': 3, '(cycle) IB': 4, '(device) MP': 5, '(device) PD': 6, '(diltiazem) DC': 7, '(drug) AC': 8, '(drug) DC': 9, '(drug) DT': 10, '(drug) ES': 11, '(drug) IT': 12, '(drug) MP': 13, '(drug) MS': 14, '(drug) NP': 15, '(drug) OR': 16, '(drug) PAC': 17, '(drug) PD': 18, '(drug) PR': 19, '(drug) RT': 20, '(grade) IA': 21, '(grade) IB': 22, '(stage) C3': 23, '(stage) IA': 24, '(stage) IB': 25, '(status) IA': 26, '(status) IB': 27, '(type) IA': 28, '(type) IB': 29, 'American Society of Anesthesiologists': 30, 'American Society of Anesthesiologists:ASA': 31, 'BK (virus)': 32, 'C-reactive': 33, 'California': 34, \"Children's Depression Inventory\": 35, 'District of Columbia': 36, 'Fairview Southdale Hospital': 37, 'GENERAL ENGLISH': 38, 'Iowa': 39, 'Los Angeles': 40, 'Louisiana': 41, 'MISTAKE:EZ PAP': 42, 'MISTAKE:Oncotype DX': 43, 'MISTAKE:abduction': 44, 'Mall of America:MOA': 45, 'NAME': 46, 'Narcotics Anonymous': 47, 'Parkinson disease': 48, 'Pneumocystis jiroveci pneumonia': 49, 'S2 (heart sound):S2': 50, 'T1 (MRI)': 51, 'T2 (MRI)': 52, 'T2 Nodes': 53, 'T3 (ECG pattern)': 54, 'UNSURED SENSE': 55, 'United States': 56, 'X-ray finding': 57, 'abdominal circumference': 58, 'abortion': 59, 'acetate': 60, 'acetyl lysergic acid diethylamide': 61, 'acetylsalicylic acid': 62, 'acromioclavicular': 63, 'ad lib on demand': 64, 'adrenoleukodystrophy': 65, 'adriamycin cyclophosphamide': 66, 'advanced maternal age': 67, 'afternoon': 68, 'against medical advice': 69, 'alanine aminotransferase:ALT': 70, 'alternating current': 71, 'aminosalicylic acid': 72, 'angiotensin-converting enzyme:ACE': 73, 'ankle-brachial': 74, 'antecubital': 75, 'anticoagulation': 76, 'antimitochondrial antibody': 77, 'antinuclear antibody:ANA': 78, 'antipyrine benzocaine': 79, 'aortic valve': 80, 'aortic valve regurgitation': 81, 'aortic valve replacement': 82, 'aortic valve resistance': 83, 'arterial blood': 84, 'arteriovenous': 85, 'arteriovenous:AV': 86, 'assist control': 87, 'atrioventricular': 88, 'atrioventricular:AV': 89, 'auditory brainstem response:ABR': 90, 'augmented voltage right arm': 91, 'basic metabolic profile': 92, 'before meals': 93, 'below knee': 94, 'beta-natriuretic peptide:BNP': 95, 'blood alcohol level': 96, 'blood group in ABO system': 97, 'bone marrow': 98, 'bone marrow transplant:BMT': 99, 'bone morphogenetic protein': 100, 'bowel movement': 101, 'breast milk': 102, 'bronchoalveolar lavage': 103, 'cancer': 104, 'cancer:CA': 105, 'carbohydrate antigen': 106, 'carcinoembryonic antigen': 107, 'carcinosarcoma:CaS': 108, 'cardiorespiratory': 109, 'cardiovascular pulmonary': 110, 'cardiovascular system': 111, 'carotid endarterectomy': 112, 'center for diagnostic imaging': 113, 'central nervous system:CNS': 114, 'central venous pressure': 115, 'cerebellopontine angle:CPA': 116, 'cerebrovascular accident': 117, 'cerebrovascular accident:CVA': 118, 'cervical (level) 3': 119, 'cervical (level) 4': 120, 'chorionic villus sampling': 121, 'clean, dry, intact': 122, 'clear to auscultation': 123, 'closed reduction': 124, 'cluster of differentiation 4:CD4': 125, 'complete remission': 126, 'computed tomographic angiography': 127, 'conjunctivae and sclerae': 128, 'controlled release': 129, 'costovertebral angle': 130, 'creatine phosphokinase:CPK': 131, 'creatinine': 132, 'culture and sensitivity': 133, 'customer, value, service': 134, 'cyclophosphamide, vincristine, prednisone': 135, 'deceased donor:DD': 136, 'deep vein thrombosis:DVT': 137, 'delirium tremens': 138, 'deoxyribonucleic acid:DNA': 139, 'desquamative interstitial pneumonia': 140, 'dextromethorphan': 141, 'diabetes mellitus': 142, 'diphtheria-tetanus': 143, 'dipropionate': 144, 'direct and consensual': 145, 'direct current': 146, 'discharge': 147, 'discontinue': 148, 'distal interphalangeal': 149, 'doppler echo:DE': 150, 'dorsalis pedis:DP': 151, 'ejection fraction:EF': 152, 'elective termination': 153, 'electroconvulsive therapy:ECT': 154, 'electrophysiology:EP': 155, 'emergency room': 156, 'endotracheal': 157, 'enhanced sensitivity': 158, 'enteric-coated': 159, 'enterocutaneous': 160, 'enterocutaneous:EC': 161, 'enterostomal therapy': 162, 'epirubicin': 163, 'erythrocyte sedimentation rate:ESR': 164, 'estrogen receptor': 165, 'extended release': 166, 'extensor carpi': 167, 'extra strength': 168, 'fascioscapulohumeral muscular dystrophy': 169, 'fluorescent in situ hybridization': 170, 'follicle-stimulating hormone': 171, 'fourth heart sound:S4': 172, 'gamma-glutamyltransferase:GGT': 173, 'gastrostomy tube': 174, 'glucose tolerance': 175, 'glutamyl transpeptidase': 176, 'gutta': 177, 'guttae:GGT': 178, 'idiopathic thrombocytopenic purpura': 179, 'idiopathic thrombocytopenic purpura:ITP': 180, 'iliotibial': 181, 'immature-to-total neutrophil': 182, 'immediate-release': 183, 'in vitro fertilization': 184, 'inferior vena cava:IVC': 185, 'information technology': 186, 'infrared': 187, 'inspiratory time': 188, 'interferon beta': 189, 'internal rotation': 190, 'international baccalaureate': 191, 'intertrochanteric': 192, 'interventional radiology': 193, 'intraarterial': 194, 'intramedullary': 195, 'intramuscular': 196, 'intrathecal': 197, 'intravenous fluid': 198, 'intravenous:IV': 199, 'ischial tuberosity': 200, 'left anterior descending:LAD': 201, 'left atrial': 202, 'left ventricle:LV': 203, 'leukocyte esterase': 204, 'long-acting': 205, 'long-acting:LA': 206, 'lower extremity': 207, 'lupus erythematosus': 208, 'lymphedema': 209, 'magnetic resonance': 210, 'master of science': 211, 'medical doctor:MD': 212, 'medical record': 213, 'medical student': 214, 'menstrual period': 215, 'mental retardation': 216, 'mercaptopurine': 217, 'mesangial proliferative': 218, 'metabolic panel': 219, 'metacarpophalangeal': 220, 'metacarpophalangeal:MP': 221, 'metarsophalangeal': 222, 'metatarsophalangeal': 223, 'metatarsophalangeal/metacarpophalangeal': 224, 'methicillin-susceptible Staphylococcus aureus': 225, 'methicillin-susceptible Staphylococcus aureus:MSSA': 226, 'military police': 227, 'milk of magnesia': 228, 'milligram:mg': 229, 'mitral regurgitation': 230, 'mitral stenosis': 231, 'modified selective severity assessment': 232, 'morphine sulfate': 233, 'multiple sclerosis': 234, 'multiples of median': 235, 'musculoskeletal': 236, 'myocardial infarction:MI': 237, 'nasopharyngeal': 238, 'nasopharynx': 239, 'natriuretic peptide': 240, 'no acute distress': 241, 'not applicable': 242, 'nothing abnormal detected': 243, 'nurse anesthetist': 244, 'nurse practitioner': 245, 'nurse practitioner:NP': 246, 'oblique presentation/occiput posterior': 247, 'occiput posterior': 248, 'operating room': 249, 'operative': 250, 'ophthalmic': 251, 'ornithine transcarbamoylase': 252, 'oropharynx': 253, 'outpatient': 254, 'ova and parasites': 255, 'over the counter': 256, 'pancreatic duct': 257, 'patent ductus': 258, 'patent ductus arteriosus': 259, 'patient-controlled analgesia:PCA': 260, 'per rectum': 261, 'peritoneal dialysis': 262, 'personality disorder': 263, 'phencyclidine': 264, 'phosphate dehydrogenase': 265, 'physical medicine and rehabilitation:PMR': 266, 'physical therapy': 267, 'physical therapy:PT': 268, 'physician assistant': 269, 'physician assistant certification': 270, 'physician associates': 271, 'picture archiving communication': 272, 'pleural effusion': 273, 'police department': 274, 'post anesthesia care': 275, 'posterior descending': 276, 'posterior descending artery': 277, 'posterior tibial': 278, 'posterior-anterior': 279, 'pr interval': 280, 'pravastatin or atorvastatin evaluation and infection therapy': 281, 'premature atrial contraction': 282, 'pressure equalization': 283, 'pressure equalization:PE': 284, 'primary care physician': 285, 'prism diopter': 286, 'progesterone receptor': 287, 'propionylcarnitine': 288, 'prostate-specific antigen:PSA': 289, 'protein C and protein S': 290, 'prothrombin': 291, 'prothrombin time': 292, 'pulmonary arterial concentration': 293, 'pulmonary artery': 294, 'pulmonary artery catheter': 295, 'pulmonary auscultation': 296, 'pulmonary embolus': 297, 'pulmonary embolus:PE': 298, 'pulmonary regurgitation': 299, 'pulse rate': 300, 'purified protein derivative:PPD': 301, 'radiation therapy': 302, 'rapid ventricular response:RVR': 303, 'respiratory therapist': 304, 'respiratory therapy': 305, 'retinoic acid': 306, 'retrograde tachycardia': 307, 'rheumatoid arthritis': 308, 'right': 309, 'right atrium': 310, 'room air': 311, 'saturation': 312, 'sequential multiple autoanalyzer': 313, 'sickle cell genotype SS': 314, 'sinemet-levodopa': 315, 'single strength': 316, 'sinuatrial': 317, 'sinus arrest': 318, 'slow acting/sustained action': 319, 'smooth muscle actin': 320, 'smooth muscle antibody': 321, 'sodium': 322, 'spinal muscular atrophy': 323, 'spontaneous bacterial peritonitis': 324, 'superior mesenteric artery': 325, 'systolic blood pressure': 326, 'term 1': 327, 'term 2': 328, 'term 3': 329, 'thoracic (level) 1': 330, 'thoracic (level) 2': 331, 'thoracic (level) 3': 332, 'thoracic (level) 4': 333, 'thyroxine': 334, 'tissue plasminogen activator:TPA': 335, 'transient ischemic attack:TIA': 336, 'triiodothyronine': 337, 'tumor stage 1': 338, 'tumor stage 2': 339, 'tumor stage 3': 340, 'tumor stage 4': 341, 'type 1 (diabetes mellitus)': 342, 'type A, type B': 343, 'ultrasound': 344, 'vascular access device': 345, 'venous blood gas': 346, 'ventricular assist device': 347, 'vertical banded gastroplasty': 348, 'video-assisted thoracic surgery:VATS': 349, 'vincristine adriamycin and dexamethasone': 350}\n",
            "Inverse Label Map: {0: '(PO Box) C4', 1: '(class) IA', 2: '(complement) component 3', 3: '(complement) component 4', 4: '(cycle) IB', 5: '(device) MP', 6: '(device) PD', 7: '(diltiazem) DC', 8: '(drug) AC', 9: '(drug) DC', 10: '(drug) DT', 11: '(drug) ES', 12: '(drug) IT', 13: '(drug) MP', 14: '(drug) MS', 15: '(drug) NP', 16: '(drug) OR', 17: '(drug) PAC', 18: '(drug) PD', 19: '(drug) PR', 20: '(drug) RT', 21: '(grade) IA', 22: '(grade) IB', 23: '(stage) C3', 24: '(stage) IA', 25: '(stage) IB', 26: '(status) IA', 27: '(status) IB', 28: '(type) IA', 29: '(type) IB', 30: 'American Society of Anesthesiologists', 31: 'American Society of Anesthesiologists:ASA', 32: 'BK (virus)', 33: 'C-reactive', 34: 'California', 35: \"Children's Depression Inventory\", 36: 'District of Columbia', 37: 'Fairview Southdale Hospital', 38: 'GENERAL ENGLISH', 39: 'Iowa', 40: 'Los Angeles', 41: 'Louisiana', 42: 'MISTAKE:EZ PAP', 43: 'MISTAKE:Oncotype DX', 44: 'MISTAKE:abduction', 45: 'Mall of America:MOA', 46: 'NAME', 47: 'Narcotics Anonymous', 48: 'Parkinson disease', 49: 'Pneumocystis jiroveci pneumonia', 50: 'S2 (heart sound):S2', 51: 'T1 (MRI)', 52: 'T2 (MRI)', 53: 'T2 Nodes', 54: 'T3 (ECG pattern)', 55: 'UNSURED SENSE', 56: 'United States', 57: 'X-ray finding', 58: 'abdominal circumference', 59: 'abortion', 60: 'acetate', 61: 'acetyl lysergic acid diethylamide', 62: 'acetylsalicylic acid', 63: 'acromioclavicular', 64: 'ad lib on demand', 65: 'adrenoleukodystrophy', 66: 'adriamycin cyclophosphamide', 67: 'advanced maternal age', 68: 'afternoon', 69: 'against medical advice', 70: 'alanine aminotransferase:ALT', 71: 'alternating current', 72: 'aminosalicylic acid', 73: 'angiotensin-converting enzyme:ACE', 74: 'ankle-brachial', 75: 'antecubital', 76: 'anticoagulation', 77: 'antimitochondrial antibody', 78: 'antinuclear antibody:ANA', 79: 'antipyrine benzocaine', 80: 'aortic valve', 81: 'aortic valve regurgitation', 82: 'aortic valve replacement', 83: 'aortic valve resistance', 84: 'arterial blood', 85: 'arteriovenous', 86: 'arteriovenous:AV', 87: 'assist control', 88: 'atrioventricular', 89: 'atrioventricular:AV', 90: 'auditory brainstem response:ABR', 91: 'augmented voltage right arm', 92: 'basic metabolic profile', 93: 'before meals', 94: 'below knee', 95: 'beta-natriuretic peptide:BNP', 96: 'blood alcohol level', 97: 'blood group in ABO system', 98: 'bone marrow', 99: 'bone marrow transplant:BMT', 100: 'bone morphogenetic protein', 101: 'bowel movement', 102: 'breast milk', 103: 'bronchoalveolar lavage', 104: 'cancer', 105: 'cancer:CA', 106: 'carbohydrate antigen', 107: 'carcinoembryonic antigen', 108: 'carcinosarcoma:CaS', 109: 'cardiorespiratory', 110: 'cardiovascular pulmonary', 111: 'cardiovascular system', 112: 'carotid endarterectomy', 113: 'center for diagnostic imaging', 114: 'central nervous system:CNS', 115: 'central venous pressure', 116: 'cerebellopontine angle:CPA', 117: 'cerebrovascular accident', 118: 'cerebrovascular accident:CVA', 119: 'cervical (level) 3', 120: 'cervical (level) 4', 121: 'chorionic villus sampling', 122: 'clean, dry, intact', 123: 'clear to auscultation', 124: 'closed reduction', 125: 'cluster of differentiation 4:CD4', 126: 'complete remission', 127: 'computed tomographic angiography', 128: 'conjunctivae and sclerae', 129: 'controlled release', 130: 'costovertebral angle', 131: 'creatine phosphokinase:CPK', 132: 'creatinine', 133: 'culture and sensitivity', 134: 'customer, value, service', 135: 'cyclophosphamide, vincristine, prednisone', 136: 'deceased donor:DD', 137: 'deep vein thrombosis:DVT', 138: 'delirium tremens', 139: 'deoxyribonucleic acid:DNA', 140: 'desquamative interstitial pneumonia', 141: 'dextromethorphan', 142: 'diabetes mellitus', 143: 'diphtheria-tetanus', 144: 'dipropionate', 145: 'direct and consensual', 146: 'direct current', 147: 'discharge', 148: 'discontinue', 149: 'distal interphalangeal', 150: 'doppler echo:DE', 151: 'dorsalis pedis:DP', 152: 'ejection fraction:EF', 153: 'elective termination', 154: 'electroconvulsive therapy:ECT', 155: 'electrophysiology:EP', 156: 'emergency room', 157: 'endotracheal', 158: 'enhanced sensitivity', 159: 'enteric-coated', 160: 'enterocutaneous', 161: 'enterocutaneous:EC', 162: 'enterostomal therapy', 163: 'epirubicin', 164: 'erythrocyte sedimentation rate:ESR', 165: 'estrogen receptor', 166: 'extended release', 167: 'extensor carpi', 168: 'extra strength', 169: 'fascioscapulohumeral muscular dystrophy', 170: 'fluorescent in situ hybridization', 171: 'follicle-stimulating hormone', 172: 'fourth heart sound:S4', 173: 'gamma-glutamyltransferase:GGT', 174: 'gastrostomy tube', 175: 'glucose tolerance', 176: 'glutamyl transpeptidase', 177: 'gutta', 178: 'guttae:GGT', 179: 'idiopathic thrombocytopenic purpura', 180: 'idiopathic thrombocytopenic purpura:ITP', 181: 'iliotibial', 182: 'immature-to-total neutrophil', 183: 'immediate-release', 184: 'in vitro fertilization', 185: 'inferior vena cava:IVC', 186: 'information technology', 187: 'infrared', 188: 'inspiratory time', 189: 'interferon beta', 190: 'internal rotation', 191: 'international baccalaureate', 192: 'intertrochanteric', 193: 'interventional radiology', 194: 'intraarterial', 195: 'intramedullary', 196: 'intramuscular', 197: 'intrathecal', 198: 'intravenous fluid', 199: 'intravenous:IV', 200: 'ischial tuberosity', 201: 'left anterior descending:LAD', 202: 'left atrial', 203: 'left ventricle:LV', 204: 'leukocyte esterase', 205: 'long-acting', 206: 'long-acting:LA', 207: 'lower extremity', 208: 'lupus erythematosus', 209: 'lymphedema', 210: 'magnetic resonance', 211: 'master of science', 212: 'medical doctor:MD', 213: 'medical record', 214: 'medical student', 215: 'menstrual period', 216: 'mental retardation', 217: 'mercaptopurine', 218: 'mesangial proliferative', 219: 'metabolic panel', 220: 'metacarpophalangeal', 221: 'metacarpophalangeal:MP', 222: 'metarsophalangeal', 223: 'metatarsophalangeal', 224: 'metatarsophalangeal/metacarpophalangeal', 225: 'methicillin-susceptible Staphylococcus aureus', 226: 'methicillin-susceptible Staphylococcus aureus:MSSA', 227: 'military police', 228: 'milk of magnesia', 229: 'milligram:mg', 230: 'mitral regurgitation', 231: 'mitral stenosis', 232: 'modified selective severity assessment', 233: 'morphine sulfate', 234: 'multiple sclerosis', 235: 'multiples of median', 236: 'musculoskeletal', 237: 'myocardial infarction:MI', 238: 'nasopharyngeal', 239: 'nasopharynx', 240: 'natriuretic peptide', 241: 'no acute distress', 242: 'not applicable', 243: 'nothing abnormal detected', 244: 'nurse anesthetist', 245: 'nurse practitioner', 246: 'nurse practitioner:NP', 247: 'oblique presentation/occiput posterior', 248: 'occiput posterior', 249: 'operating room', 250: 'operative', 251: 'ophthalmic', 252: 'ornithine transcarbamoylase', 253: 'oropharynx', 254: 'outpatient', 255: 'ova and parasites', 256: 'over the counter', 257: 'pancreatic duct', 258: 'patent ductus', 259: 'patent ductus arteriosus', 260: 'patient-controlled analgesia:PCA', 261: 'per rectum', 262: 'peritoneal dialysis', 263: 'personality disorder', 264: 'phencyclidine', 265: 'phosphate dehydrogenase', 266: 'physical medicine and rehabilitation:PMR', 267: 'physical therapy', 268: 'physical therapy:PT', 269: 'physician assistant', 270: 'physician assistant certification', 271: 'physician associates', 272: 'picture archiving communication', 273: 'pleural effusion', 274: 'police department', 275: 'post anesthesia care', 276: 'posterior descending', 277: 'posterior descending artery', 278: 'posterior tibial', 279: 'posterior-anterior', 280: 'pr interval', 281: 'pravastatin or atorvastatin evaluation and infection therapy', 282: 'premature atrial contraction', 283: 'pressure equalization', 284: 'pressure equalization:PE', 285: 'primary care physician', 286: 'prism diopter', 287: 'progesterone receptor', 288: 'propionylcarnitine', 289: 'prostate-specific antigen:PSA', 290: 'protein C and protein S', 291: 'prothrombin', 292: 'prothrombin time', 293: 'pulmonary arterial concentration', 294: 'pulmonary artery', 295: 'pulmonary artery catheter', 296: 'pulmonary auscultation', 297: 'pulmonary embolus', 298: 'pulmonary embolus:PE', 299: 'pulmonary regurgitation', 300: 'pulse rate', 301: 'purified protein derivative:PPD', 302: 'radiation therapy', 303: 'rapid ventricular response:RVR', 304: 'respiratory therapist', 305: 'respiratory therapy', 306: 'retinoic acid', 307: 'retrograde tachycardia', 308: 'rheumatoid arthritis', 309: 'right', 310: 'right atrium', 311: 'room air', 312: 'saturation', 313: 'sequential multiple autoanalyzer', 314: 'sickle cell genotype SS', 315: 'sinemet-levodopa', 316: 'single strength', 317: 'sinuatrial', 318: 'sinus arrest', 319: 'slow acting/sustained action', 320: 'smooth muscle actin', 321: 'smooth muscle antibody', 322: 'sodium', 323: 'spinal muscular atrophy', 324: 'spontaneous bacterial peritonitis', 325: 'superior mesenteric artery', 326: 'systolic blood pressure', 327: 'term 1', 328: 'term 2', 329: 'term 3', 330: 'thoracic (level) 1', 331: 'thoracic (level) 2', 332: 'thoracic (level) 3', 333: 'thoracic (level) 4', 334: 'thyroxine', 335: 'tissue plasminogen activator:TPA', 336: 'transient ischemic attack:TIA', 337: 'triiodothyronine', 338: 'tumor stage 1', 339: 'tumor stage 2', 340: 'tumor stage 3', 341: 'tumor stage 4', 342: 'type 1 (diabetes mellitus)', 343: 'type A, type B', 344: 'ultrasound', 345: 'vascular access device', 346: 'venous blood gas', 347: 'ventricular assist device', 348: 'vertical banded gastroplasty', 349: 'video-assisted thoracic surgery:VATS', 350: 'vincristine adriamycin and dexamethasone'}\n",
            "Total labels: 351\n",
            "Total Inverse Label: 351\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of training samples: {len(texts_train)}\")\n",
        "print(f\"Number of test samples: {len(texts_test)}\")\n",
        "print(\"Example of processed data:\")\n",
        "print(texts_train[0], labels_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Js5_ddGtK6vR",
        "outputId": "997d1d43-6171-4f65-eb50-204e14eb8181"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples: 30000\n",
            "Number of test samples: 7500\n",
            "Example of processed data:\n",
            "Will get his home medications and continue those. Will ask neurology to review his antiepileptic regimen and have spoken with Dr. _%#NAME#%_. We will have OT and PT evaluate the patient. Suspect that he may need a TCU versus home with additional services. LABORATORY DATA: That was performed here includes the following laboratory tests. 267\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch\n",
        "\n",
        "class ClinicalTextDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# Load the pretrained BioBERT Tokenizer and Model\n",
        "tokenizer = BertTokenizer.from_pretrained('dmis-lab/biobert-v1.1')\n",
        "model = BertForSequenceClassification.from_pretrained('dmis-lab/biobert-v1.1', num_labels=len(label_map))\n",
        "\n",
        "# Ensure all texts are strings before passing them to the tokenizer\n",
        "texts_train = [str(text) for text in texts_train]\n",
        "texts_test = [str(text) for text in texts_test]\n",
        "\n",
        "# Encode the texts\n",
        "train_encodings = tokenizer(texts_train, truncation=True, padding=True, max_length=128)\n",
        "test_encodings = tokenizer(texts_test, truncation=True, padding=True, max_length=128)\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = ClinicalTextDataset(train_encodings, labels_train)\n",
        "test_dataset = ClinicalTextDataset(test_encodings, labels_test)\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=16,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=100,\n",
        ")\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset\n",
        ")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the pretrained BioBERT model without training\n",
        "zero_shot_model = BertForSequenceClassification.from_pretrained('dmis-lab/biobert-v1.1', num_labels=len(label_map))\n",
        "zero_shot_model.to(device)\n",
        "\n",
        "# Create a DataLoader for the test dataset for zero-shot evaluation\n",
        "zero_shot_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# Initialize variables for tracking zero-shot accuracy\n",
        "zero_shot_correct = 0\n",
        "zero_shot_total = 0\n",
        "\n",
        "# Evaluate the model without training\n",
        "for batch in zero_shot_loader:\n",
        "    batch = {k: v.to(device) for k, v in batch.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = zero_shot_model(**batch)\n",
        "    pred_indices = outputs.logits.argmax(-1).tolist()\n",
        "    actual_indices = batch['labels'].tolist()\n",
        "    zero_shot_correct += sum(p == a for p, a in zip(pred_indices, actual_indices))\n",
        "    zero_shot_total += len(batch['labels'])\n",
        "\n",
        "zero_shot_accuracy = (zero_shot_correct / zero_shot_total) * 100\n",
        "print(f\"Zero-shot accuracy before training: {zero_shot_accuracy:.2f}%\")\n",
        "\n",
        "\n",
        "# Start training\n",
        "trainer.train()\n",
        "\n",
        "# Save the fine-tuned model and tokenizer\n",
        "model_path = \"./biobert_finetuned\"\n",
        "model.save_pretrained(model_path)\n",
        "tokenizer.save_pretrained(model_path)\n",
        "\n",
        "# Verify the number of labels in the model configuration\n",
        "print(\"Expected number of labels (from label map):\", len(label_map))\n",
        "print(\"Number of labels in model configuration:\", model.config.num_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Vm38fsggLFem",
        "outputId": "501d52f4-de1e-49b2-b76c-77314e0aa737"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dmis-lab/biobert-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dmis-lab/biobert-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zero-shot accuracy before training: 0.12%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3750' max='3750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3750/3750 14:00, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>5.859600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>5.525000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>5.181900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>4.865700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>4.450600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>3.887600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>3.270000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>2.711500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>2.274000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.841500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>1.609400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>1.392700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>1.292400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>1.196100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>1.067300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>1.088900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.979100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.937100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.781200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.752800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.707200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.715300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.602400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.787300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.576100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.492000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.532700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.635500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.561100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.537600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.593400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.637600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.508000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.490200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.520900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.514400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.571100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected number of labels (from label map): 351\n",
            "Number of labels in model configuration: 351\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a data loader for the training dataset\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=False)  # Batch size can be adjusted based on GPU capacity\n",
        "\n",
        "# Initialize variables for tracking accuracy\n",
        "correct_predictions_train = 0\n",
        "total_predictions_train = 0\n",
        "\n",
        "# Iterate over the training data\n",
        "for batch in train_loader:\n",
        "    # Move the batch data to the appropriate device\n",
        "    batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "    # Perform inference without computing gradients\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**batch)\n",
        "\n",
        "    # Get the predicted class indices with the highest logit values\n",
        "    pred_indices = outputs.logits.argmax(-1).tolist()\n",
        "\n",
        "    # Compare predicted results with actual labels and count correct predictions\n",
        "    actual_indices = batch['labels'].tolist()\n",
        "    correct_predictions_train += sum(p == a for p, a in zip(pred_indices, actual_indices))\n",
        "    total_predictions_train += len(batch['labels'])\n",
        "\n",
        "# Calculate and print the accuracy of the model on the training data\n",
        "accuracy_train = (correct_predictions_train / total_predictions_train) * 100\n",
        "print(f\"Accuracy of trained model on training data: {accuracy_train:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zb-EPyviQtCx",
        "outputId": "43b15954-b818-41d7-83c3-24234497ae6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of trained model on training data: 91.44%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import torch\n",
        "from transformers import BertForSequenceClassification\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Create a data loader for the test dataset\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# Initialize variables for tracking accuracy\n",
        "correct_predictions = 0\n",
        "total_predictions = 0\n",
        "\n",
        "# Iterate over the test data\n",
        "for batch in test_loader:\n",
        "    # Move the batch data to the appropriate device\n",
        "    batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "    # Perform inference without computing gradients\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**batch)\n",
        "\n",
        "    # Get the predicted class indices with the highest logit values\n",
        "    pred_indices = outputs.logits.argmax(-1).tolist()\n",
        "\n",
        "    # Compare predicted results with actual labels and count correct predictions\n",
        "    actual_indices = batch['labels'].tolist()\n",
        "    correct_predictions += sum(p == a for p, a in zip(pred_indices, actual_indices))\n",
        "    total_predictions += len(batch['labels'])\n",
        "\n",
        "# Calculate and print the accuracy of the model on the test data\n",
        "accuracy = (correct_predictions / total_predictions) * 100\n",
        "print(f\"Accuracy of trained BioBERT model: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhsgHc46OEQ8",
        "outputId": "07dfd930-9b2f-43a4-ef7c-a119b885c1d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of trained BioBERT model: 90.97%\n"
          ]
        }
      ]
    }
  ]
}